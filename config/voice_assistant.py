#!/usr/bin/env python3
import os
import subprocess
import whisper
import sounddevice as sd
from scipy.io.wavfile import write
import requests
import json
import torch
from TTS.api import TTS  # Coqui TTS

# =====================
# é…ç½®å‚æ•°
# =====================
SAMPLERATE = 16000
RECORD_SECONDS = 5
LLAMA_API = "http://localhost:11434/api/generate"
AUDIO_FILE = "input.wav"
TTS_FILE = "out.wav"

# =====================
# åŠ è½½ Whisper æ¨¡å‹
# =====================
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ”Š æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ï¼ˆsmallï¼‰åœ¨ {device} ä¸Š...")
model = whisper.load_model("small", device=device)

# =====================
# TTSï¼šCoqui TTS (GPU)
# =====================
print("ğŸ”Š æ­£åœ¨åŠ è½½ Coqui TTS æ¨¡å‹...")
# ä½¿ç”¨ä¸­æ–‡ GPU æ¨¡å‹
tts = TTS(model_name="tts_models/zh-CN/baker/tacotron2-DDC", gpu=True, progress_bar=False)

def speak(text: str):
    try:
        # ç”Ÿæˆè¯­éŸ³åˆ°æ–‡ä»¶
        tts.tts_to_file(text=text, file_path=TTS_FILE)
        # æ’­æ”¾ç”Ÿæˆçš„éŸ³é¢‘
        subprocess.run(["aplay", TTS_FILE], check=True)
    except Exception as e:
        print(f"âš ï¸ TTS å¤±è´¥: {e}")

# =====================
# å½•éŸ³
# =====================
def record_audio(seconds=RECORD_SECONDS, path=AUDIO_FILE):
    print("ğŸ™ï¸ æ­£åœ¨å½•éŸ³...")
    try:
        data = sd.rec(int(SAMPLERATE * seconds), samplerate=SAMPLERATE, channels=1, dtype='int16')
        sd.wait()
        write(path, SAMPLERATE, data)
    except Exception as e:
        print(f"âš ï¸ å½•éŸ³å¤±è´¥: {e}")
        return None
    print("âœ… å½•éŸ³å®Œæˆã€‚")
    return path

# =====================
# Whisper ä¸­æ–‡è¯†åˆ«
# =====================
def speech_to_text(audio_path):
    if not audio_path or not os.path.exists(audio_path):
        return ""
    try:
        result = model.transcribe(audio_path, language='zh')
        return result.get("text", "").strip()
    except Exception as e:
        print(f"âš ï¸ Whisper è¯†åˆ«å¤±è´¥: {e}")
        return ""

# =====================
# Ollama ä¸­æ–‡èŠå¤©
# =====================
def query_llm(prompt):
    prompt = f"è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š{prompt}"
    try:
        resp = requests.post(LLAMA_API, json={"model": "qwen3:1.7b", "prompt": prompt}, stream=True, timeout=10)
        full_response = ""
        for line in resp.iter_lines():
            if not line:
                continue
            try:
                js = json.loads(line.decode("utf-8"))
                full_response += js.get("response", "")
            except json.JSONDecodeError:
                continue
        return full_response.strip() or "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£ã€‚"
    except Exception as e:
        print(f"âš ï¸ Ollama è°ƒç”¨å¤±è´¥: {e}")
        return "æŠ±æ­‰ï¼Œæ— æ³•è·å¾—å›ç­”"

# =====================
# æ‰§è¡Œç³»ç»Ÿå‘½ä»¤
# =====================
def execute_command(cmd):
    try:
        subprocess.Popen(cmd, shell=True)
        return f"å·²æ‰§è¡Œå‘½ä»¤ï¼š{cmd}"
    except Exception as e:
        return f"æ‰§è¡Œå¤±è´¥ï¼š{e}"

# =====================
# ä¸»å¾ªç¯ï¼ˆè¿ç»­ç›‘å¬ï¼‰
# =====================
def main():
    speak("ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„æœ¬åœ°è¯­éŸ³åŠ©æ‰‹ï¼Œå·²å¯åŠ¨ï¼Œè¯·ç›´æ¥è¯´è¯ã€‚")
    while True:
        audio_path = record_audio()
        text = speech_to_text(audio_path)
        print(f"ğŸ—£ï¸ è¯†åˆ«ç»“æœ: {text}")

        if not text:
            speak("æˆ‘æ²¡æœ‰å¬æ¸…ï¼Œè¯·å†è¯´ä¸€éã€‚")
            continue

        # é€€å‡ºå‘½ä»¤
        if "é€€å‡º" in text or "å†è§" in text:
            speak("å¥½çš„ï¼Œå†è§ï¼")
            break
        # æ‰“å¼€åº”ç”¨
        elif "æ‰“å¼€" in text:
            app = text.replace("æ‰“å¼€", "").strip()
            reply = execute_command(app)
        # é»˜è®¤èŠå¤©
        else:
            reply = query_llm(text)

        print(f"ğŸ¤–ï¼š{reply}")
        speak(reply)

# =====================
# å¯åŠ¨
# =====================
if __name__ == "__main__":
    main()

